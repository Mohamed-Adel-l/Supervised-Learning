{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBR+XLR4dBIQB+nmvHks4Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed-Adel-l/Supervised-Learning/blob/main/LogisticRegression_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score , confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "AMdUDqIFgQnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rice_dataset_raw = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/Rice_Cammeo_Osmancik.csv\")\n",
        "x=rice_dataset_raw.drop('Class',axis=1)\n",
        "y=rice_dataset_raw['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "print(rice_dataset_raw.describe())\n",
        "print(\"\\nData Shapes:\\n\" + \"-\" * 40)\n",
        "print(f\"{'X_train shape':<15}: {X_train.shape}\")\n",
        "print(f\"{'X_test shape' :<15}: {X_test.shape}\")\n",
        "print(f\"{'y_train shape':<15}: {y_train.shape}\")\n",
        "print(f\"{'y_test shape' :<15}: {y_test.shape}\")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "print(\"\\nLabel Encoding Map:\\n\" + \"-\" * 40)\n",
        "for class_name, class_id in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
        "    print(f\"{class_name:<10} → {class_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrThdhMLxslS",
        "outputId": "a9757d6d-a2ed-4572-c0b2-f0004060ed5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Area    Perimeter  Major_Axis_Length  Minor_Axis_Length  \\\n",
            "count   3810.000000  3810.000000        3810.000000        3810.000000   \n",
            "mean   12667.727559   454.239180         188.776222          86.313750   \n",
            "std     1732.367706    35.597081          17.448679           5.729817   \n",
            "min     7551.000000   359.100006         145.264465          59.532406   \n",
            "25%    11370.500000   426.144753         174.353855          82.731695   \n",
            "50%    12421.500000   448.852493         185.810059          86.434647   \n",
            "75%    13950.000000   483.683746         203.550438          90.143677   \n",
            "max    18913.000000   548.445984         239.010498         107.542450   \n",
            "\n",
            "       Eccentricity   Convex_Area       Extent  \n",
            "count   3810.000000   3810.000000  3810.000000  \n",
            "mean       0.886871  12952.496850     0.661934  \n",
            "std        0.020818   1776.972042     0.077239  \n",
            "min        0.777233   7723.000000     0.497413  \n",
            "25%        0.872402  11626.250000     0.598862  \n",
            "50%        0.889050  12706.500000     0.645361  \n",
            "75%        0.902588  14284.000000     0.726562  \n",
            "max        0.948007  19099.000000     0.861050  \n",
            "\n",
            "Data Shapes:\n",
            "----------------------------------------\n",
            "X_train shape  : (3048, 7)\n",
            "X_test shape   : (762, 7)\n",
            "y_train shape  : (3048,)\n",
            "y_test shape   : (762,)\n",
            "\n",
            "Label Encoding Map:\n",
            "----------------------------------------\n",
            "Cammeo     → 0\n",
            "Osmancik   → 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "scaler=StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "class Batch_Gradient_Descent:\n",
        "  def __init__(self, learning_rate=0.001, n_iters=1000):\n",
        "    self.lr = learning_rate\n",
        "    self.n_iters = n_iters\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def loss(self, y, y_pred):\n",
        "    return (-y*np.log(y_pred) - (1-y)*np.log(1-y_pred)).mean()\n",
        "  def fit(self, X, y):\n",
        "    self.weights =np.zeros(X.shape[1])\n",
        "    self.bias = 0\n",
        "    self.losses = []\n",
        "    for i in range(self.n_iters):\n",
        "      z_pred = np.dot(X, self.weights) + self.bias\n",
        "      y_pred = self.sigmoid(z_pred)\n",
        "      dw = (1/X.shape[0])*np.dot(X.T, (y_pred-y))\n",
        "      db = (1/X.shape[0])*np.sum(y_pred-y)\n",
        "      self.weights -= self.lr*dw\n",
        "      self.bias -= self.lr*db\n",
        "      self.losses.append(self.loss(y, y_pred))\n",
        "      print(f\"epoch:{i+1}/{self.n_iters}, loss:{self.losses[-1]}\")\n",
        "  def predict(self, X):\n",
        "    z_pred = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = self.sigmoid(z_pred)\n",
        "    y_pred = np.where(y_pred>0.5, 1, 0)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "ikGkR4mdx436"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mini_batch_gradient_descent:\n",
        "  def __init__(self, learning_rate=0.001, n_iters=1000, batch_size=32):\n",
        "    self.lr = learning_rate\n",
        "    self.n_iters = n_iters\n",
        "    self.batch_size = batch_size\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def loss(self, y, y_pred):\n",
        "    return (-y*np.log(y_pred) - (1-y)*np.log(1-y_pred)).mean()\n",
        "  def fit(self, X, y):\n",
        "    self.weights =np.zeros(X.shape[1])\n",
        "    self.bias = 0\n",
        "    self.losses = []\n",
        "    n_samples=X.shape[0]\n",
        "    for i in range(self.n_iters):\n",
        "     indices = np.arange(n_samples)\n",
        "     np.random.shuffle(indices)\n",
        "     X = X[indices]\n",
        "     y = y[indices]\n",
        "     for j in range(0, n_samples, self.batch_size):\n",
        "       X_batch = X[j:j+self.batch_size]\n",
        "       y_batch = y[j:j+self.batch_size]\n",
        "       z_pred = np.dot(X_batch, self.weights) + self.bias\n",
        "       y_pred = self.sigmoid(z_pred)\n",
        "       dw = (1/self.batch_size)*np.dot(X_batch.T, (y_pred-y_batch))\n",
        "       db = (1/self.batch_size)*np.sum(y_pred-y_batch)\n",
        "       self.weights -= self.lr*dw\n",
        "       self.bias -= self.lr*db\n",
        "       self.losses.append(self.loss(y_batch, y_pred))\n",
        "     print(f\"epoch:{i+1}/{self.n_iters}, loss:{self.losses[-1]}\")\n",
        "  def predict(self, X):\n",
        "    y_pred = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = self.sigmoid(y_pred)\n",
        "    y_pred = np.where(y_pred>0.5, 1, 0)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "hLE3gZN-yKDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Stochastic_gradient_descent:\n",
        "  def __init__(self, learning_rate=0.001, n_iters=1000):\n",
        "    self.lr = learning_rate\n",
        "    self.n_iters = n_iters\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def loss(self, y, y_pred):\n",
        "    return (-y*np.log(y_pred) - (1-y)*np.log(1-y_pred)).mean()\n",
        "  def fit(self, X, y):\n",
        "    self.weights =np.zeros(X.shape[1])\n",
        "    self.bias = 0\n",
        "    self.losses = []\n",
        "    n_samples=X.shape[0]\n",
        "    for i in range(self.n_iters):\n",
        "     indices = np.arange(n_samples)\n",
        "     np.random.shuffle(indices)\n",
        "     X_shuffled = X[indices]\n",
        "     y_shuffled= y[indices]\n",
        "     for j in range(n_samples):\n",
        "       X_j = X_shuffled[j].reshape(1, -1)\n",
        "       y_j = y_shuffled[j]\n",
        "       z_pred = np.dot(X_j, self.weights) + self.bias\n",
        "       y_pred = self.sigmoid(z_pred)\n",
        "       dw = np.dot(X_j.T, (y_pred-y_j))\n",
        "       db = np.sum(y_pred-y_j)\n",
        "       self.weights -= self.lr*dw\n",
        "       self.bias -= self.lr*db\n",
        "       self.losses.append(self.loss(y_j, y_pred))\n",
        "     print(f\"epoch:{i+1}/{self.n_iters}, loss:{self.losses[-1]}\")\n",
        "  def predict(self, X):\n",
        "    z_pred = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = self.sigmoid(z_pred)\n",
        "    y_pred = np.where(y_pred>0.5, 1, 0)\n",
        "    return y_pred\n"
      ],
      "metadata": {
        "id": "XJOuha6rydfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Batch_Gradient_Descent(learning_rate=0.01, n_iters=10)\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model1.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\" + \"-\" * 30)\n",
        "print(cm)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\\n\" + \"-\" * 30)\n",
        "print(f\"{'Accuracy' :<10}: {acc:.4f}\")\n",
        "print(f\"{'Precision':<10}: {prec:.4f}\")\n",
        "print(f\"{'Recall'   :<10}: {rec:.4f}\")\n",
        "print(f\"{'F1 Score' :<10}: {f1:.4f}\")\n",
        "results['BGD'] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt31BytuypL-",
        "outputId": "a6a58b32-d78a-4fef-9bbb-1548914c35c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1/10, loss:0.6931471805599454\n",
            "epoch:2/10, loss:0.6859784498399223\n",
            "epoch:3/10, loss:0.6789686275814459\n",
            "epoch:4/10, loss:0.6721140603671435\n",
            "epoch:5/10, loss:0.6654111313974577\n",
            "epoch:6/10, loss:0.6588562648063736\n",
            "epoch:7/10, loss:0.6524459295717169\n",
            "epoch:8/10, loss:0.6461766430308731\n",
            "epoch:9/10, loss:0.6400449740147822\n",
            "epoch:10/10, loss:0.634047545614724\n",
            "\n",
            "Confusion Matrix:\n",
            "------------------------------\n",
            "[[323  27]\n",
            " [ 36 376]]\n",
            "\n",
            "Evaluation Metrics:\n",
            "------------------------------\n",
            "Accuracy  : 0.9173\n",
            "Precision : 0.9330\n",
            "Recall    : 0.9126\n",
            "F1 Score  : 0.9227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Mini_batch_gradient_descent(learning_rate=0.01, n_iters=10, batch_size=2)\n",
        "model2.fit(X_train, y_train)\n",
        "y_pred = model2.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\" + \"-\" * 30)\n",
        "print(cm)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\\n\" + \"-\" * 30)\n",
        "print(f\"{'Accuracy' :<10}: {acc:.4f}\")\n",
        "print(f\"{'Precision':<10}: {prec:.4f}\")\n",
        "print(f\"{'Recall'   :<10}: {rec:.4f}\")\n",
        "print(f\"{'F1 Score' :<10}: {f1:.4f}\")\n",
        "results['MBGD'] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BrRORVWzyvO",
        "outputId": "7d0266a5-e0b4-497d-a85c-8c26c8ac63e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1/10, loss:0.20466251868941504\n",
            "epoch:2/10, loss:0.03476396557710363\n",
            "epoch:3/10, loss:0.01644810926420136\n",
            "epoch:4/10, loss:0.12352480818784094\n",
            "epoch:5/10, loss:0.220347293070528\n",
            "epoch:6/10, loss:0.000568692678460896\n",
            "epoch:7/10, loss:0.01751331325846595\n",
            "epoch:8/10, loss:0.044985992404816606\n",
            "epoch:9/10, loss:0.1479109049703373\n",
            "epoch:10/10, loss:0.008993169907107652\n",
            "\n",
            "Confusion Matrix:\n",
            "------------------------------\n",
            "[[324  26]\n",
            " [ 29 383]]\n",
            "\n",
            "Evaluation Metrics:\n",
            "------------------------------\n",
            "Accuracy  : 0.9278\n",
            "Precision : 0.9364\n",
            "Recall    : 0.9296\n",
            "F1 Score  : 0.9330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3= Stochastic_gradient_descent(learning_rate=0.01, n_iters=10)\n",
        "model3.fit(X_train, y_train)\n",
        "y_pred = model3.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\" + \"-\" * 30)\n",
        "print(cm)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\\n\" + \"-\" * 30)\n",
        "print(f\"{'Accuracy' :<10}: {acc:.4f}\")\n",
        "print(f\"{'Precision':<10}: {prec:.4f}\")\n",
        "print(f\"{'Recall'   :<10}: {rec:.4f}\")\n",
        "print(f\"{'F1 Score' :<10}: {f1:.4f}\")\n",
        "results['SGD'] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvXbDDfz1KJJ",
        "outputId": "89d73fe7-9a1f-4abd-c30b-1f1a0d827a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1/10, loss:1.1741183695467\n",
            "epoch:2/10, loss:0.007132458306796421\n",
            "epoch:3/10, loss:0.005755558686656315\n",
            "epoch:4/10, loss:0.0028311840923905215\n",
            "epoch:5/10, loss:0.007624223556303398\n",
            "epoch:6/10, loss:0.0032009374401818637\n",
            "epoch:7/10, loss:0.10872303370709462\n",
            "epoch:8/10, loss:0.04006737357247391\n",
            "epoch:9/10, loss:0.051592705020749786\n",
            "epoch:10/10, loss:0.04291991826214951\n",
            "\n",
            "Confusion Matrix:\n",
            "------------------------------\n",
            "[[322  28]\n",
            " [ 22 390]]\n",
            "\n",
            "Evaluation Metrics:\n",
            "------------------------------\n",
            "Accuracy  : 0.9344\n",
            "Precision : 0.9330\n",
            "Recall    : 0.9466\n",
            "F1 Score  : 0.9398\n"
          ]
        }
      ]
    }
  ]
}